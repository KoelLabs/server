# Use the official Python image as the base
FROM python:3.10.12-slim-buster

# Set the working directory in the container
WORKDIR /app

# Download and cache the pre-trained model(s)
ARG HF_TOKEN
ENV HF_TOKEN=${HF_TOKEN}
ENV HF_HUB_CACHE=/app/.cache/huggingface/hub
RUN pip install transformers==4.47.0 torch==2.5.1
RUN python -c "from transformers import AutoProcessor, AutoModelForCTC; model_id = 'KoelLabs/xlsr-timit-b0'; AutoProcessor.from_pretrained(model_id); AutoModelForCTC.from_pretrained(model_id)"

# Copy the requirements file into the container
COPY requirements.txt requirements.txt

# Install the required packages
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code into the container
COPY . .

# Expose the port that the Flask app will run on
EXPOSE 8080

# Define the command to run the Flask app
CMD gunicorn --workers=$((2 * $(python -c 'import os; print(os.cpu_count())') + 1)) --threads=1 --bind=0.0.0.0:8080 --timeout 600 --chdir src server:app
